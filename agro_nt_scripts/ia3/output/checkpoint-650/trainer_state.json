{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.857997010463378,
  "eval_steps": 50,
  "global_step": 650,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.37,
      "grad_norm": 19.928356170654297,
      "learning_rate": 0.0002816793893129771,
      "loss": 4.8747,
      "step": 50
    },
    {
      "epoch": 0.75,
      "grad_norm": 12.761950492858887,
      "learning_rate": 0.00025877862595419845,
      "loss": 3.8514,
      "step": 100
    },
    {
      "epoch": 1.12,
      "grad_norm": 9.186643600463867,
      "learning_rate": 0.00023587786259541982,
      "loss": 3.6731,
      "step": 150
    },
    {
      "epoch": 1.49,
      "grad_norm": 14.9457426071167,
      "learning_rate": 0.0002129770992366412,
      "loss": 3.5056,
      "step": 200
    },
    {
      "epoch": 1.87,
      "grad_norm": 14.474433898925781,
      "learning_rate": 0.00019007633587786257,
      "loss": 3.4605,
      "step": 250
    },
    {
      "epoch": 2.24,
      "grad_norm": 4.544258117675781,
      "learning_rate": 0.00016717557251908396,
      "loss": 3.3667,
      "step": 300
    },
    {
      "epoch": 2.62,
      "grad_norm": 28.58966636657715,
      "learning_rate": 0.00014427480916030534,
      "loss": 3.4346,
      "step": 350
    },
    {
      "epoch": 2.99,
      "grad_norm": 1.0653005838394165,
      "learning_rate": 0.00012137404580152671,
      "loss": 3.2439,
      "step": 400
    },
    {
      "epoch": 3.36,
      "grad_norm": 30.34299659729004,
      "learning_rate": 9.847328244274808e-05,
      "loss": 3.3024,
      "step": 450
    },
    {
      "epoch": 3.74,
      "grad_norm": 0.9329410791397095,
      "learning_rate": 7.557251908396945e-05,
      "loss": 3.2362,
      "step": 500
    },
    {
      "epoch": 4.11,
      "grad_norm": 3.47357439994812,
      "learning_rate": 5.267175572519083e-05,
      "loss": 3.1882,
      "step": 550
    },
    {
      "epoch": 4.48,
      "grad_norm": 3.828738212585449,
      "learning_rate": 2.977099236641221e-05,
      "loss": 3.1849,
      "step": 600
    },
    {
      "epoch": 4.86,
      "grad_norm": 11.608023643493652,
      "learning_rate": 6.870229007633587e-06,
      "loss": 3.1286,
      "step": 650
    }
  ],
  "logging_steps": 50,
  "max_steps": 665,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 50,
  "total_flos": 1.2515148617314222e+18,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
